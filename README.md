# Real-Time-Virtual-Mouse-Using-Hand-Gestures
Real-Time Virtual Mouse Using Hand Gestures is an innovative system that utilizes Convolutional Neural Networks (CNN), Image Processing, OpenCV, and Mediapipe to control a virtual mouse using hand gestures. This technology enables users to interact with computers or devices without the need for physical mouse or touchpad. By capturing and analyzing real-time hand movements and gestures, the system accurately detects and interprets the user's hand motions, allowing them to move the cursor, click, drag-drop, and multi-select functions. This intuitive and hands-free approach enhances user experience and opens up possibilities for more natural and immersive human-computer interaction.    
Tech-stack:  
Framework: Tkinter  
Backend: Python  


Prerequisites:  
Python 3.9.x  


Installation:  
Create a new virtual environment:  
$ python -m venv venv  

Activate the virtual environment:  
$ source venv/bin/activate  (For Linux)  
$ venv/Scripts/activate  (For Windows)  

Install Packages:  
import tkinter  
import cv2  
import mediapipe  
import pyautogui  
import ctypes   
import comtypes   
import pycaw.pycaw   

git remote add origin https://github.com/NehaSabrin/Real-Time-Virtual-Mouse-Using-Hand-Gesturesesturs.git  
